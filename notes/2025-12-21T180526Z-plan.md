# Plan: Modularize VM tests and add RAID/LVM cleanup coverage

## Context
- `tests/test_boot_image_vm.py` is ~2.7k lines mixing fixtures, helpers, controller logic, and scenarios.
- VM-based cleanup regression (Task 2) needs a reliable, runnable flow without hangs/timeouts.
- Prior runs hung/failed; need recorded, stepwise progress to avoid losing work.

## Goals
- Break the monolithic VM test into focused modules without behavior changes.
- Implement the RAID/LVM residue regression test (Task 2) using the new structure.
- Keep VM runs tractable and reproducible; record every attempt and outcome.

## Phased plan

1) **Inventory and define module boundaries**
   - Catalogue fixtures and helpers currently in `tests/test_boot_image_vm.py` (tools/ISO/disks fixtures, SSH key handling, metadata writers, `BootImageVM` controller, command utilities, test cases).
   - Proposed modules:
     - `tests/vm/fixtures.py` – tool checks, ISO build, disk image fixtures, SSH key generation.
     - `tests/vm/metadata.py` – metadata/diagnostic helpers.
     - `tests/vm/controller.py` – `BootImageVM` class and interaction helpers.
     - `tests/vm/cleanup_plan.py` – RAID/LVM cleanup utilities shared by scenarios.
     - `tests/vm/test_pre_nixos_vm.py` – existing scenarios (split out from monolith).
     - `tests/vm/test_pre_nixos_cleanup.py` – new RAID/LVM residue regression scenario.
   - Maintain fixture names/scopes for compatibility during the split.

2) **Mechanical split with compatibility layer**
   - Move helpers/dataclasses into new modules; adjust imports in-place.
   - Optionally keep a thin shim (`tests/test_boot_image_vm.py` or `tests/vm/conftest.py`) re-exporting fixtures to minimize churn.

3) **Add RAID/LVM cleanup regression test (Task 2)**
   - Preseed mdadm+LVM residue inside the VM (simulate `/dev/md127` leftovers).
   - Run `pre-nixos` end-to-end; assert cleanup succeeds and post-run layout matches plan.
   - Capture artifacts on failure: dmesg, pre-nixos logs, disko output.

4) **Runtime management and reliability**
   - Surface timeout env vars (`BOOT_IMAGE_VM_SPAWN_TIMEOUT`, `BOOT_IMAGE_VM_LOGIN_TIMEOUT`) in helpers to tune runs.
   - Add markers (`@pytest.mark.vm`, `@pytest.mark.slow`) and document selective invocation; do not silently skip—treat missing tools/timeouts as failures and record them.
   - Reuse built ISO across scenarios; keep disk sizes minimal while safe.

5) **Documentation**
   - Add `tests/vm/README.md` explaining module layout, required tools, env vars, and how to run VM tests.
   - Keep run logs/attempts in `notes/` with UTC timestamps; include commands and outcomes to avoid losing progress.

6) **Iterative execution loop**
   - After splitting, run existing VM test + new cleanup test; collect outputs.
   - Apply half-splitting on failures; iterate fixes with logs per run.
   - Once stable, remove legacy monolith wrapper if superseded by new modules.

## Immediate next steps
- Extract fixtures/controller/metadata into `tests/vm/` modules per above.
- Add README outlining run instructions and markers.
- Implement cleanup regression test using shared helpers.
- Execute VM tests, record results in `notes/` with timestamps; iterate until green.

## Work log stubs (fill as we execute)
- [ ] **Inventory snapshot** – dump a table of current fixtures/helpers and their scopes before moving them.
- [ ] **Module skeletons** – create empty `tests/vm/*.py` files with docstrings describing intended contents; wire `__init__.py` if needed.
- [ ] **Shim plan** – decide whether `tests/vm/conftest.py` or the legacy file re-exports fixtures; document chosen approach.
- [ ] **RAID/LVM recipe** – write the exact mdadm/LVM commands that will seed leftover devices inside the VM (include cleanup expectations).
- [ ] **Timeout defaults** – codify sensible default values for spawn/login timeouts and note how to override via env vars.
- [ ] **Run ledger** – capture each VM test attempt with UTC timestamp, command, result, and any artifacts collected.
